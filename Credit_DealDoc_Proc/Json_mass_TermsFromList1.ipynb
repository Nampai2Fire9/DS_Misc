{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library import\n",
    "import os\n",
    "import re\n",
    "import pdfplumber\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import json\n",
    "import tabula  #for table processing\n",
    "from itertools import islice # iterates through directions\n",
    "import json\n",
    "os.chdir(r'C:\\Users\\Owner\\OneDrive\\Research_Git\\DS_Misc\\Credit_DealDoc_Proc')\n",
    "import scrape\n",
    "import logging  # from error logs\n",
    "\n",
    "logger = logging.Logger('catch_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable multiple output per cell. \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "os.chdir(r'C:\\Users\\Owner\\OneDrive\\Digital Mosaic\\Product\\Solutions\\Vibrant\\Deal_Docs\\definitions')\n",
    "json_file_list = ['PAIA.json','THL_CW_2019.json','Carlyle 2019-1.json', 'Crestline.json']\n",
    "file_name_list = ['PAIA 2018-1 - Indenture (730498612_1).pdf', \n",
    "                  'THL 2019-3 - Indenture (with exhibits).pdf',\n",
    "                 'Carlyle 2019-1 Indenture (Executed).pdf',\n",
    "                 'Crestline Denali CLO XVII, Ltd-Indenture.pdf']\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from deal specs file. \n",
    "os.chdir(r'C:\\Users\\Owner\\OneDrive\\Digital Mosaic\\Product\\Solutions\\Vibrant\\Deal_Docs\\definitions')\n",
    "deal_specs = pd.read_csv('deal_level_filespecs.csv')\n",
    "json_file_list = list(deal_specs['json_file'])\n",
    "file_name_list = list(deal_specs['pdf_file_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=cyan> Process Deal Docs within dictionary </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vibrant_VIII.json Vibrant VIII - Indenture(133849278_1).pdf\n",
      "Vibrant_IX.json Vibrant CLO IX - Indenture.pdf\n",
      "Vibrant_X.json Vibrant CLO X - Indenture(137699931_1)[1].pdf\n",
      "PAIA.json PAIA 2018-1 - Indenture (730498612_1).pdf\n",
      "Crestline.json Crestline Denali CLO XVII, Ltd-Indenture.pdf\n",
      "THL_CW_2019.json THL 2019-3 - Indenture (with exhibits).pdf\n",
      "Carlyle 2019-1.json Carlyle 2019-1 Indenture (Executed).pdf\n",
      "OHA2.json OHA Credit Funding 2 - Indenture(141188118_1).pdf\n",
      "OHA11.json ohacp11-INDENTURE-2015-11-30-755682.pdf\n",
      "OHA_XII.json OHA XII Indenture.pdf\n"
     ]
    }
   ],
   "source": [
    "deal_docs_dict = {}\n",
    "for i in np.arange(0, len(json_file_list)):\n",
    "    json_file_name = json_file_list[i]\n",
    "    og_file_name = file_name_list[i]\n",
    "    print(json_file_name, og_file_name)\n",
    "    deal_docs_dict[og_file_name] = {}\n",
    "    deal_docs_dict[og_file_name]['json_file_name'] = json_file_name\n",
    "    with open(json_file_name) as json_ind:\n",
    "        deal_doc = json.load(json_ind)\n",
    "    deal_docs_dict[og_file_name]['deal_doc'] = deal_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['fileName', 'fileType', 'deal', 'status', 'indenture', '_id'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['_id', 'fileName', 'fileType', 'deal', 'status', 'indenture'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['_id', 'fileName', 'fileType', 'deal', 'status', 'indenture'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['_id', 'fileName', 'fileType', 'deal', 'status', 'indenture'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['fileName', 'fileType', 'deal', 'status', 'indenture', '_id'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['fileName', 'fileType', 'deal', 'status', 'indenture', '_id'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['fileName', 'fileType', 'deal', 'status', 'indenture', '_id'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['fileName', 'fileType', 'deal', 'status', 'indenture', '_id'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['fileName', 'fileType', 'deal', 'status', 'indenture', '_id'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['fileName', 'fileType', 'deal', 'status', 'indenture', '_id'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, file_name in enumerate(file_name_list):\n",
    "    deal_docs_dict[file_name]['deal_doc'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=magenta>Rename \"text\" to \"definition\"</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'        \\nfor key in jdict[\\'indenture\\'][\\'terms\\'].keys():\\n    new_name = key.replace(\"U.S.\", \"US\")\\n    jdict[\\'indenture\\'][\\'terms\\'][new_name] = jdict[\\'indenture\\'][\\'terms\\'].pop(key)\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, file_name in enumerate(file_name_list):\n",
    "    for j, item in enumerate(deal_docs_dict[file_name]['deal_doc']['indenture']['terms']):\n",
    "        item['definition'] = item.pop('text')\n",
    "\"\"\"        \n",
    "for key in jdict['indenture']['terms'].keys():\n",
    "    new_name = key.replace(\"U.S.\", \"US\")\n",
    "    jdict['indenture']['terms'][new_name] = jdict['indenture']['terms'].pop(key)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['term', 'systemTerm', 'page', 'def_values', 'definition'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['term', 'systemTerm', 'page', 'def_values', 'definition'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['term', 'systemTerm', 'page', 'def_values', 'definition'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['term', 'systemTerm', 'page', 'def_values', 'definition'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['term', 'systemTerm', 'page', 'def_values', 'definition'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['term', 'systemTerm', 'page', 'def_values', 'definition'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['term', 'systemTerm', 'page', 'def_values', 'definition'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['term', 'systemTerm', 'page', 'def_values', 'definition'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['term', 'systemTerm', 'page', 'def_values', 'definition'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['term', 'systemTerm', 'page', 'def_values', 'definition'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test first definition \n",
    "for i, file_name in enumerate(file_name_list):\n",
    "    deal_docs_dict[file_name]['deal_doc']['indenture']['terms'][0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Mapping table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>def_name</th>\n",
       "      <th>systemTerm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17g-5 Information</td>\n",
       "      <td>17g-5 Information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17g-5 Information Agent</td>\n",
       "      <td>17g-5 Information Agent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17g-5 Information Agent's Website</td>\n",
       "      <td>17g-5 Website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17g-5 Information Agent's Website</td>\n",
       "      <td>17g-5 Website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17g-5 Information Provider</td>\n",
       "      <td>17g-5 Information Agent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            def_name               systemTerm\n",
       "0                  17g-5 Information        17g-5 Information\n",
       "1            17g-5 Information Agent  17g-5 Information Agent\n",
       "2  17g-5 Information Agent's Website            17g-5 Website\n",
       "3  17g-5 Information Agent's Website            17g-5 Website\n",
       "4         17g-5 Information Provider  17g-5 Information Agent"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import mapping table \n",
    "os.chdir(r'C:\\Users\\Owner\\OneDrive\\Digital Mosaic\\Product\\Solutions\\Vibrant\\Deal_Docs\\definitions')\n",
    "df_fldmap = pd.read_csv('Deal_def_columns_fld_map2.csv', encoding='cp1252')\n",
    "df_fldmap.columns = ['def_name', 'systemTerm']\n",
    "df_fldmap.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>def_name</th>\n",
       "      <th>systemTerm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17g-5 Information</td>\n",
       "      <td>17g-5 Information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17g-5 Information Agent</td>\n",
       "      <td>17g-5 Information Agent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17g-5 Information Agent's Website</td>\n",
       "      <td>17g-5 Website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17g-5 Information Agent's Website</td>\n",
       "      <td>17g-5 Website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17g-5 Information Provider</td>\n",
       "      <td>17g-5 Information Agent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            def_name               systemTerm\n",
       "0                  17g-5 Information        17g-5 Information\n",
       "1            17g-5 Information Agent  17g-5 Information Agent\n",
       "2  17g-5 Information Agent's Website            17g-5 Website\n",
       "3  17g-5 Information Agent's Website            17g-5 Website\n",
       "4         17g-5 Information Provider  17g-5 Information Agent"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adjust any quotes in imported names \n",
    "def_og_name_map = [x.replace(\"’\", \"'\") for x in df_fldmap['def_name']]\n",
    "df_fldmap['def_name'] = def_og_name_map\n",
    "df_fldmap.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test if any names are not mapped in file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'term': 'IRS',\n",
       " 'systemTerm': 'IRS',\n",
       " 'page': 50,\n",
       " 'text': '  United States Internal Revenue Service. ',\n",
       " 'def_values': '  United States Internal Revenue Service. '}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['PAIA 2018-1 - Indenture (730498612_1).pdf', 'THL 2019-3 - Indenture (with exhibits).pdf', 'Carlyle 2019-1 Indenture (Executed).pdf', 'Crestline Denali CLO XVII, Ltd-Indenture.pdf'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deal_docs_dict[file_name_list[0]]['deal_doc']['indenture']['terms'][0]\n",
    "deal_docs_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmapped names in Deal:  0 0\n",
      "Unmapped names in Deal:  1 0\n",
      "Unmapped names in Deal:  2 0\n",
      "Unmapped names in Deal:  3 0\n"
     ]
    }
   ],
   "source": [
    "for n, file_name in enumerate(file_name_list):\n",
    "    # test_list = []\n",
    "    not_mapped = []\n",
    "    for i, item_dict in enumerate(deal_docs_dict[file_name]['deal_doc']['indenture']['terms']):\n",
    "    # for i, key in enumerate(deal_doc['indenture']['terms'].keys()):\n",
    "        key_stage = item_dict['term']\n",
    "        key_stage = key_stage.replace('  ',' ')\n",
    "        key_stage = key_stage.replace(\"”\", '')\n",
    "        key_stage = key_stage.replace(\"“\", '')\n",
    "        key_stage = key_stage.replace(\"’\", \"'\")\n",
    "        key_stage = key_stage.replace('\"', '') \n",
    "        new_name = df_fldmap[df_fldmap['def_name']==key_stage]['systemTerm'].values\n",
    "        if new_name.size == 0:   # check if value not mapped \n",
    "            print(key,'|', key_stage)\n",
    "            not_mapped.append(item_dict['term'])\n",
    "    print(\"Unmapped names in Deal: \", n, len(test_list))\n",
    "    # test_list.append(new_name[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Section 1\n",
    "1. Load logic for <font color=deepskyblue> Table of Contents </font> \n",
    "2. Isolate Section 1 string\n",
    "3. Pull bullet points for section 1, <font color=deeppink>excluding Section 1.1</font>\n",
    "4. add back into deal_doc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Article 2', 'Article 3', 'Article 4', 'Article 5', 'Article 6', 'Article 7', 'Article 8', 'Article 9', 'Article 10', 'Article 11', 'Article 12', 'Article 13', 'Article 14', 'Article 15', 'Article 1'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deal_docs_dict[file_name_list[0]]['deal_doc']['indenture']['Sections'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\Owner\\OneDrive\\Digital Mosaic\\Product\\Solutions\\Vibrant\\Deal_Docs')\n",
    "toc_start_page_list = [1, 1, 1, 1]\n",
    "toc_end_page_list = [7,7,8,8]\n",
    "toc_pages_dict = {}\n",
    "for i, file_name in enumerate(file_name_list):\n",
    "    toc_pages_dict[file_name] = {}\n",
    "    toc_pages_dict[file_name]['toc_pages'] = scrape.pdf_extract_pages(file_name, toc_start_page_list[i], toc_end_page_list[i])\n",
    "    toc_pages_dict[file_name]['toc_str'] = scrape.combine_strings(toc_pages_dict[file_name]['toc_pages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Carlyle 2019-1 Indenture (Executed).pdf'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name_list[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "toc_dict_list = {}  # will hold list of toc dictionaries\n",
    "num_sections = [16,15,16, 15]\n",
    "for n, file_name in enumerate(file_name_list):\n",
    "    toc_dict = {}     # deal level toc dictionary with page numbers for each section\n",
    "    sec1_name_list = []\n",
    "    regex_page = r'\\.*\\d+'\n",
    "    try:\n",
    "        for i in np.arange(1, num_sections[n]+1):\n",
    "            article_name = \"ARTICLE \" + str(i)\n",
    "            regex_sec1 = \"\\nSection \" + str(i) + r\".1(\\.?)\"\n",
    "            regex_sec1 = regex_sec1 + r\"(\\s+).*(\\.*)(\\d+)\"\n",
    "            # print(regex_sec1) \n",
    "            match = re.search(regex_sec1, toc_pages_dict[file_name]['toc_str'])\n",
    "                # process page numbers\n",
    "            pg_str = toc_pages_dict[file_name]['toc_str'][match.span()[1]-5:match.span()[1]]\n",
    "            pg_loc = re.search(regex_page, pg_str)\n",
    "            pg_num = pg_str[pg_loc.span()[0]:pg_loc.span()[1]]\n",
    "            pg_num = pg_num.replace('.','')\n",
    "            pg_num = int(pg_num) \n",
    "            toc_dict[article_name] = pg_num \n",
    "    except:\n",
    "        pass\n",
    "    toc_dict_list[file_name] = toc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PAIA 2018-1 - Indenture (730498612_1).pdf': {'ARTICLE 1': 3,\n",
       "  'ARTICLE 2': 82,\n",
       "  'ARTICLE 3': 107,\n",
       "  'ARTICLE 4': 113,\n",
       "  'ARTICLE 5': 115,\n",
       "  'ARTICLE 6': 130,\n",
       "  'ARTICLE 7': 145,\n",
       "  'ARTICLE 8': 170,\n",
       "  'ARTICLE 9': 178,\n",
       "  'ARTICLE 10': 188,\n",
       "  'ARTICLE 11': 211,\n",
       "  'ARTICLE 12': 222,\n",
       "  'ARTICLE 13': 231,\n",
       "  'ARTICLE 14': 232,\n",
       "  'ARTICLE 15': 242,\n",
       "  'ARTICLE 16': 244},\n",
       " 'THL 2019-3 - Indenture (with exhibits).pdf': {'ARTICLE 1': 2,\n",
       "  'ARTICLE 2': 85,\n",
       "  'ARTICLE 3': 111,\n",
       "  'ARTICLE 4': 117,\n",
       "  'ARTICLE 5': 119,\n",
       "  'ARTICLE 6': 133,\n",
       "  'ARTICLE 7': 147,\n",
       "  'ARTICLE 8': 170,\n",
       "  'ARTICLE 9': 178,\n",
       "  'ARTICLE 10': 190,\n",
       "  'ARTICLE 11': 210,\n",
       "  'ARTICLE 12': 218,\n",
       "  'ARTICLE 13': 226,\n",
       "  'ARTICLE 14': 227,\n",
       "  'ARTICLE 15': 238},\n",
       " 'Carlyle 2019-1 Indenture (Executed).pdf': {'ARTICLE 1': 2,\n",
       "  'ARTICLE 2': 78,\n",
       "  'ARTICLE 3': 108,\n",
       "  'ARTICLE 4': 114,\n",
       "  'ARTICLE 5': 118,\n",
       "  'ARTICLE 6': 131,\n",
       "  'ARTICLE 7': 146,\n",
       "  'ARTICLE 8': 168,\n",
       "  'ARTICLE 9': 178,\n",
       "  'ARTICLE 10': 189,\n",
       "  'ARTICLE 11': 210,\n",
       "  'ARTICLE 12': 219,\n",
       "  'ARTICLE 13': 228,\n",
       "  'ARTICLE 14': 229,\n",
       "  'ARTICLE 15': 238},\n",
       " 'Crestline Denali CLO XVII, Ltd-Indenture.pdf': {'ARTICLE 1': 2,\n",
       "  'ARTICLE 2': 67,\n",
       "  'ARTICLE 3': 91,\n",
       "  'ARTICLE 4': 98,\n",
       "  'ARTICLE 5': 101,\n",
       "  'ARTICLE 6': 113,\n",
       "  'ARTICLE 7': 125,\n",
       "  'ARTICLE 8': 146,\n",
       "  'ARTICLE 9': 154,\n",
       "  'ARTICLE 10': 164,\n",
       "  'ARTICLE 11': 179,\n",
       "  'ARTICLE 12': 187,\n",
       "  'ARTICLE 13': 194,\n",
       "  'ARTICLE 14': 195,\n",
       "  'ARTICLE 15': 203}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toc_dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PAIA 2018-1 - Indenture (730498612_1).pdf',\n",
       " 'THL 2019-3 - Indenture (with exhibits).pdf',\n",
       " 'Carlyle 2019-1 Indenture (Executed).pdf',\n",
       " 'Crestline Denali CLO XVII, Ltd-Indenture.pdf']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate section_pages list \n",
    "opening_length = [8, 8, 7, 7]  # pages to add to toc page numbers\n",
    "sec_page_last = [252, 247, 245, 211]  # denotes last page before schedules\n",
    "section_page_list = {}  # dictionary holding section pages for each file\n",
    "for n, file_name in enumerate(toc_dict_list.keys()):\n",
    "    section_pages = []\n",
    "    for i in np.arange(2, len(toc_dict_list[file_name].keys())+1): \n",
    "        art_str = 'ARTICLE ' + str(i)\n",
    "        section_pages.append(toc_dict_list[file_name][art_str])\n",
    "    # add opening length to section pages\n",
    "    section_pages = [x + opening_length[n] for x in section_pages]   # add opening length (# of pages in title + toc) to each page\n",
    "    section_page_list[file_name] = section_pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Isolate Section 1 string and parse bullet points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAIA 2018-1 - Indenture (730498612_1).pdf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THL 2019-3 - Indenture (with exhibits).pdf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carlyle 2019-1 Indenture (Executed).pdf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crestline Denali CLO XVII, Ltd-Indenture.pdf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get article 2 first page \n",
    "for i, file_name in enumerate(file_name_list):\n",
    "    print(file_name) \n",
    "    section_page_list[file_name][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate first section\n",
    "first_page_list = [84, 88, 78, 67]  # pages for Section 1.2 start. find page and subract one \n",
    "art1_pages_dict = {}\n",
    "for i, file_name in enumerate(file_name_list):\n",
    "    art1_pages_dict[file_name] = {}\n",
    "    art1_pages_dict[file_name]['art1_pages'] = scrape.pdf_extract_pages(file_name, first_page_list[i], section_page_list[file_name][0])\n",
    "    art1_pages_dict[file_name]['art1_str'] = scrape.combine_strings(art1_pages_dict[file_name]['art1_pages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec1_regex_list = [r'[\\n\\s]Section 1.2(\\.?\\s)', \n",
    "                   r'[\\n\\s]Section 1.3(\\.?\\s)', r'[\\n\\s]Section 1.4(\\.?\\s)',\n",
    "                  r'[\\n\\s]Section 1.5(\\.?\\s)', r'[\\n\\s]Section 1.6(\\.?\\s)',\n",
    "                  r'[\\n\\s]Section 1.7(\\.?\\s)', r'[\\n\\s]Section 1.8(\\.?\\s)',\n",
    "                  r'[\\n\\s]Section 1.9(\\.?\\s)',r'[\\n\\s]Section 1.10(\\.?\\s)',\n",
    "                  r'[\\n\\s]Section 1.11(\\.?\\s)', r'[\\n\\s]Section 1.12(\\.?\\s)',\n",
    "                  r'[\\n\\s]Section 1.13(\\.?\\s)', r'[\\n\\s]Section 1.14(\\.?\\s)',\n",
    "                  r'[\\n\\s]Section 1.15(\\.?\\s)', r'[\\n\\s]Section 1.16(\\.?\\s)',\n",
    "                  r'[\\n\\s]Section 1.17(\\.?\\s)', r'[\\n\\s]Section 1.18(\\.?\\s)',\n",
    "                  r'[\\n\\s]Section 1.19(\\.?\\s)', r'[\\n\\s]Section 1.20(\\.?\\s)',\n",
    "                  r'[\\n\\s]Section 1.21(\\.?\\s)', r'[\\n\\s]Section 1.22(\\.?\\s)',\n",
    "                  r'[\\n\\s]Section 1.23(\\.?\\s)', r'[\\n\\s]Section 1.24(\\.?\\s)',\n",
    "                  r'[\\n\\s]Section 1.25(\\.?\\s)', r'[\\n\\s]Section 1.26(\\.?\\s)',\n",
    "                  r'[\\n\\s]Section 1.27(\\.?\\s)', r'[\\n\\s]Section 1.28(\\.?\\s)',\n",
    "                  r'[\\n\\s]Section 1.29(\\.?\\s)', r'[\\n\\s]Section 1.30(\\.?\\s)']\n",
    "# numdec_list = ['1.','1.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get end locations for article 1\n",
    "regex_art2 = r'\\nARTICLE (2|II)(\\s?)\\n'\n",
    "# art1_end_list = []\n",
    "for i, file_name in enumerate(file_name_list):\n",
    "    try:\n",
    "        art1_pages_dict[file_name]['art1_end'] = re.search(regex_art2, art1_pages_dict[file_name]['art1_str']).span()[0]\n",
    "    except:\n",
    "        pass\n",
    "    # art1_end = re.search(regex_art2, art1_str).span()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAIA 2018-1 - Indenture (730498612_1).pdf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['art1_pages', 'art1_str', 'art1_end'])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THL 2019-3 - Indenture (with exhibits).pdf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['art1_pages', 'art1_str', 'art1_end'])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carlyle 2019-1 Indenture (Executed).pdf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['art1_pages', 'art1_str', 'art1_end'])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crestline Denali CLO XVII, Ltd-Indenture.pdf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['art1_pages', 'art1_str', 'art1_end'])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, file_name in enumerate(file_name_list):\n",
    "    print(file_name)\n",
    "    art1_pages_dict[file_name].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1_2', '1_3']\n",
      "['1_2', '1_3']\n",
      "['1_2', '1_3']\n",
      "['1_2', '1_3']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor i, bullet in enumerate(artfirst_bullets):\\n    artfirst_dict[sec1_bullet_names[i]] = bullet\\n'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# art1_pages_dict['Vibrant CLO X - Indenture(137699931_1)[1].pdf'].keys()\n",
    "art1_name = '1_Definition'\n",
    "art1first_dict = {}\n",
    "for i, file_name in enumerate(file_name_list):\n",
    "    art1first_dict[file_name] = {}\n",
    "    art1first_dict[file_name]['Name'] = art1_name\n",
    "    # art1_pages_dict[file_name]['art1_bullets'] = scrape.list_btn_loc_regexlist_keepbullet2_order(art1_pages_dict[file_name]['art1_str'],\n",
    "    #                                                 art1_pages_dict[file_name]['art1_end'], sec1_regex_list)\n",
    "    try:\n",
    "        art1_bullets = scrape.list_btn_loc_regexlist_keepbullet2_order(art1_pages_dict[file_name]['art1_str'],\n",
    "                                                        art1_pages_dict[file_name]['art1_end'], sec1_regex_list)    \n",
    "        bullet_names = ['1_' + str(x) for x in np.arange(len(art1_bullets)) + 2]\n",
    "        print(bullet_names)\n",
    "        for j, bullet in enumerate(art1_bullets):\n",
    "            art1first_dict[file_name][bullet_names[j]] = bullet\n",
    "    except BaseException as e:\n",
    "        print(file_name)\n",
    "        logger.error('Failed to do something: ' + str(e))\n",
    "\"\"\"\n",
    "for i, bullet in enumerate(artfirst_bullets):\n",
    "    artfirst_dict[sec1_bullet_names[i]] = bullet\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate deal_doc \n",
    "for i, file_name in enumerate(file_name_list):\n",
    "    deal_docs_dict[file_name]['deal_doc']['indenture']['Sections']['Article 1'] = art1first_dict[file_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Crestline Denali CLO XVII'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['Name', '1_2', '1_3'])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see sample \n",
    "deal_docs_dict[file_name_list[3]]['deal_doc']['_id']\n",
    "deal_docs_dict[file_name_list[3]]['deal_doc']['indenture']['Sections']['Article 1'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-create original definition dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['term', 'systemTerm', 'page', 'def_values', 'definition'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deal_docs_dict[file_name_list[0]]['deal_doc']['indenture']['terms'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If terms are in list of dictionaries and def_names are within each dict. \n",
    "df_def_dict = {}\n",
    "for i, file_name in enumerate(file_name_list):\n",
    "    # df_def_dict[file_name] = {}\n",
    "    df_def = pd.DataFrame(columns = ['def_name', 'def_description'])\n",
    "    def_description = []\n",
    "    systemTerms = []\n",
    "    def_name = [] \n",
    "    for i, item in enumerate(deal_docs_dict[file_name]['deal_doc']['indenture']['terms']):\n",
    "        def_name.append(item['term'])\n",
    "        def_description.append(item['definition'])\n",
    "        systemTerms.append(item['systemTerm'])\n",
    "    df_def['def_name'] = def_name\n",
    "    df_def['def_description'] = def_description\n",
    "    df_def['systemTerm'] = systemTerms\n",
    "    df_def_dict[file_name] = df_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create cleaned up version of def_description\n",
    "for i, file_name in enumerate(file_name_list):\n",
    "    def_descr_clean = [x.replace('\\n','') for x in df_def_dict[file_name]['def_description']]\n",
    "    def_descr_clean = [x.replace('  ', ' ') for x in def_descr_clean]\n",
    "    df_def_dict[file_name]['def_descr_clean'] = def_descr_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'   The meaning  specified  in Section 8.7. '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(426, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_def_dict[file_name_list[1]]['def_description'][0]\n",
    "df_def_dict[file_name_list[1]].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Isolate meaning reference definitions into separate dictionary ```df_def_dict```**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = r\"The(\\s+)meaning(\\s+)specified(\\s+)in(\\s+)Section(\\s+)(\\d+)((\\.\\d+)?)[\\.(\\(\\w\\)]\"\n",
    "for i, file_name in enumerate(file_name_list):\n",
    "    mean_ref = [x.replace('  ',' ') for x in df_def_dict[file_name]['def_descr_clean']]\n",
    "    mean_ref = [re.search(regex,x) for x in mean_ref]  # find any definition referencing another section\n",
    "    mean_ref2 = [df_def_dict[file_name]['def_descr_clean'].iloc[i] if item is not None else item for i, item in enumerate(mean_ref)]\n",
    "    df_def_dict[file_name]['reference_def'] = mean_ref2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dictionary holding only referenced definition\n",
    "df_refdefs_dict = {} \n",
    "for i, file_name in enumerate(file_name_list):\n",
    "    df_refdefs = df_def_dict[file_name][['def_name','reference_def']][df_def_dict[file_name]['reference_def'].notnull()].copy()\n",
    "    df_refdefs_dict[file_name] = df_refdefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color = salmon> Remove any references to 'the Code' since it does not reference another section.</font>** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_code_list = [' of the Code', 'of the Investment Company Act', ' of the Management Agreement',\n",
    "                  'of the Collateral Management Agreement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vibrant VIII - Indenture(133849278_1).pdf :  []\n",
      "Vibrant VIII - Indenture(133849278_1).pdf :  ['Qualified  Purchaser']\n",
      "Vibrant VIII - Indenture(133849278_1).pdf :  []\n",
      "Vibrant VIII - Indenture(133849278_1).pdf :  []\n",
      "Vibrant CLO IX - Indenture.pdf :  []\n",
      "Vibrant CLO IX - Indenture.pdf :  ['Qualified Purchaser']\n",
      "Vibrant CLO IX - Indenture.pdf :  []\n",
      "Vibrant CLO IX - Indenture.pdf :  []\n",
      "Vibrant CLO X - Indenture(137699931_1)[1].pdf :  []\n",
      "Vibrant CLO X - Indenture(137699931_1)[1].pdf :  ['Qualified Purchaser']\n",
      "Vibrant CLO X - Indenture(137699931_1)[1].pdf :  []\n",
      "Vibrant CLO X - Indenture(137699931_1)[1].pdf :  []\n",
      "PAIA 2018-1 - Indenture (730498612_1).pdf :  ['US Person']\n",
      "PAIA 2018-1 - Indenture (730498612_1).pdf :  []\n",
      "PAIA 2018-1 - Indenture (730498612_1).pdf :  []\n",
      "PAIA 2018-1 - Indenture (730498612_1).pdf :  []\n",
      "Crestline Denali CLO XVII, Ltd-Indenture.pdf :  []\n",
      "Crestline Denali CLO XVII, Ltd-Indenture.pdf :  []\n",
      "Crestline Denali CLO XVII, Ltd-Indenture.pdf :  ['Principal Trade', 'Independent  Review  Party']\n",
      "Crestline Denali CLO XVII, Ltd-Indenture.pdf :  []\n",
      "THL 2019-3 - Indenture (with exhibits).pdf :  []\n",
      "THL 2019-3 - Indenture (with exhibits).pdf :  ['Qualified  Purchaser']\n",
      "THL 2019-3 - Indenture (with exhibits).pdf :  []\n",
      "THL 2019-3 - Indenture (with exhibits).pdf :  []\n",
      "Carlyle 2019-1 Indenture (Executed).pdf :  []\n",
      "Carlyle 2019-1 Indenture (Executed).pdf :  []\n",
      "Carlyle 2019-1 Indenture (Executed).pdf :  []\n",
      "Carlyle 2019-1 Indenture (Executed).pdf :  ['Deferred  Subordinated  Management  Fee']\n",
      "OHA Credit Funding 2 - Indenture(141188118_1).pdf :  ['US Person']\n",
      "OHA Credit Funding 2 - Indenture(141188118_1).pdf :  ['Qualified  Purchaser']\n",
      "OHA Credit Funding 2 - Indenture(141188118_1).pdf :  []\n",
      "OHA Credit Funding 2 - Indenture(141188118_1).pdf :  []\n",
      "ohacp11-INDENTURE-2015-11-30-755682.pdf :  ['US Person']\n",
      "ohacp11-INDENTURE-2015-11-30-755682.pdf :  ['Qualified  Purchaser']\n",
      "ohacp11-INDENTURE-2015-11-30-755682.pdf :  []\n",
      "ohacp11-INDENTURE-2015-11-30-755682.pdf :  []\n",
      "OHA XII Indenture.pdf :  ['US Person']\n",
      "OHA XII Indenture.pdf :  ['Qualified  Purchaser']\n",
      "OHA XII Indenture.pdf :  []\n",
      "OHA XII Indenture.pdf :  []\n"
     ]
    }
   ],
   "source": [
    "for i, file_name in enumerate(file_name_list):\n",
    "    # Remove any reference \"the Code\"\n",
    "    for regex_code in regex_code_list:\n",
    "        # regex_code = ' of the Code'\n",
    "        # isolate any definition referencing code \n",
    "        def_code_ref = [df_refdefs_dict[file_name]['def_name'].iloc[i] for i, x in enumerate(df_refdefs_dict[file_name]['reference_def']) if re.search(regex_code, x) is not None]\n",
    "        print(file_name, ': ', def_code_ref)\n",
    "        for i, item in enumerate(def_code_ref):\n",
    "            df_refdefs_dict[file_name] = df_refdefs_dict[file_name][df_refdefs_dict[file_name]['def_name'] != item]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=salmon>Seperate out sections, sub-sections, and Article number. Example for 10.3(a), section would be 10_3, sub_section: a, Article: 10</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vibrant VIII - Indenture(133849278_1).pdf\n",
      "Vibrant CLO IX - Indenture.pdf\n",
      "Vibrant CLO X - Indenture(137699931_1)[1].pdf\n",
      "PAIA 2018-1 - Indenture (730498612_1).pdf\n",
      "Crestline Denali CLO XVII, Ltd-Indenture.pdf\n",
      "THL 2019-3 - Indenture (with exhibits).pdf\n",
      "Carlyle 2019-1 Indenture (Executed).pdf\n",
      "OHA Credit Funding 2 - Indenture(141188118_1).pdf\n",
      "ohacp11-INDENTURE-2015-11-30-755682.pdf\n",
      "OHA XII Indenture.pdf\n"
     ]
    }
   ],
   "source": [
    "regex = r\"The(\\s+)meaning(\\s+)specified(\\s+)in(\\s+)Section(\\s+)(\\d+)((\\.\\d+)?)[\\.(\\(\\w\\)]\"\n",
    "regex_section = r\"(\\s+\\d+)((\\.\\d+)?)((\\(\\w\\))?)\"\n",
    "regex_sect_top = r\"(\\s+\\d+)((\\.\\d+)?)\"   # example: 10.3\n",
    "regex_sub_sect = r\"\\(\\w+\\)\"\n",
    "regex_article = r\"\\d+(\\.?)\"\n",
    "# grab end of section matching regex \n",
    "for i, file_name in enumerate(file_name_list):\n",
    "    print(file_name)\n",
    "    # Grab section numbers \n",
    "    section_nums = [x[re.search(regex,x).span()[1]-7:re.search(regex,x).span()[1]+3] \n",
    "                    for x in df_refdefs_dict[file_name]['reference_def']]\n",
    "    section_num= [x[re.search(regex_section, x).span()[0]:re.search(regex_section, x).span()[1]] for x in section_nums]\n",
    "    section_num = [x.replace(' ', '') for x in section_num]\n",
    "    section_num = [x.replace('\\n','') for x in section_num]\n",
    "    \n",
    "    # Grab section numbers: example: 10_3 \n",
    "    sect_num_top= [x[re.search(regex_sect_top, x).span()[0]:re.search(regex_sect_top, x).span()[1]] for x in section_nums]\n",
    "    sect_num_top = [x.replace(' ', '') for x in sect_num_top]  \n",
    "    sect_num_top = [x. replace('.','_') for x in sect_num_top]\n",
    "    \n",
    "    #Grab section sub-sections: example: for 10.3(b), return b\n",
    "    sect_num_sub = []\n",
    "    for i, item in enumerate(section_nums):\n",
    "        item = str(item)\n",
    "        try:\n",
    "            sect_sub = item[re.search(regex_sub_sect, item).span()[0]:re.search(regex_sub_sect, item).span()[1]] \n",
    "            sect_sub = sect_sub.replace(')','')\n",
    "            sect_sub = sect_sub.replace('(','')\n",
    "            sect_num_sub.append(sect_sub)\n",
    "        except:\n",
    "            sect_num_sub.append(None)\n",
    "    \n",
    "    # Grab Article number \n",
    "    article_num = [x[re.search(regex_article,x).span()[0]:re.search(regex_article,x).span()[1]] for x in sect_num_top]\n",
    "    article_num = [x.replace('.','') for x in article_num]\n",
    "    \n",
    "    df_refdefs_dict[file_name]['section_num'] = section_num\n",
    "    df_refdefs_dict[file_name]['sect_num_top'] = sect_num_top\n",
    "    df_refdefs_dict[file_name]['sect_num_sub'] = sect_num_sub\n",
    "    df_refdefs_dict[file_name]['article_num'] = article_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attach definitions from <font color=cyan> Sections dictionary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Crestline Denali CLO XVII, Ltd-Indenture.pdf'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>def_name</th>\n",
       "      <th>reference_def</th>\n",
       "      <th>section_num</th>\n",
       "      <th>sect_num_top</th>\n",
       "      <th>sect_num_sub</th>\n",
       "      <th>article_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Moody's Ramp-Up Failure</td>\n",
       "      <td>The meaning specified in Section 7.20(c).</td>\n",
       "      <td>7.20(c)</td>\n",
       "      <td>7_20</td>\n",
       "      <td>c</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Passing Report</td>\n",
       "      <td>The meaning specified in Section 7.20(c).</td>\n",
       "      <td>7.20(c)</td>\n",
       "      <td>7_20</td>\n",
       "      <td>c</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Priority of Partial Redemption Proceeds</td>\n",
       "      <td>The meaning specified in Section 11.1(a)(iv).</td>\n",
       "      <td>11.1(a)</td>\n",
       "      <td>11_1</td>\n",
       "      <td>a</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Process Agent</td>\n",
       "      <td>The meaning specified in Section 7.2.</td>\n",
       "      <td>7.2</td>\n",
       "      <td>7_2</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Reset Amendment</td>\n",
       "      <td>The meaning specified in Section 8.2(a).</td>\n",
       "      <td>8.2(a)</td>\n",
       "      <td>8_2</td>\n",
       "      <td>a</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    def_name  \\\n",
       "30                   Moody's Ramp-Up Failure   \n",
       "63                            Passing Report   \n",
       "86   Priority of Partial Redemption Proceeds   \n",
       "89                             Process Agent   \n",
       "128                          Reset Amendment   \n",
       "\n",
       "                                      reference_def section_num sect_num_top  \\\n",
       "30        The meaning specified in Section 7.20(c).     7.20(c)         7_20   \n",
       "63        The meaning specified in Section 7.20(c).     7.20(c)         7_20   \n",
       "86    The meaning specified in Section 11.1(a)(iv).     11.1(a)         11_1   \n",
       "89            The meaning specified in Section 7.2.         7.2          7_2   \n",
       "128        The meaning specified in Section 8.2(a).      8.2(a)          8_2   \n",
       "\n",
       "    sect_num_sub article_num  \n",
       "30             c           7  \n",
       "63             c           7  \n",
       "86             a          11  \n",
       "89          None           7  \n",
       "128            a           8  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name_list[4]\n",
    "df_refdefs_dict[file_name_list[4]].iloc[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0, df_refdefs_dict[file_name_list[0]].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 Carlyle 2019-1 Indenture (Executed).pdf 34 Article 1 1_4  errored on Section Match\n"
     ]
    }
   ],
   "source": [
    "for i, file_name in enumerate(file_name_list):\n",
    "    ref_section_def = []\n",
    "    try:\n",
    "        for j in np.arange(0, df_refdefs_dict[file_name].shape[0]):\n",
    "            art_str = 'Article ' + str(df_refdefs_dict[file_name]['article_num'].iloc[j])\n",
    "            sect_num_top = df_refdefs_dict[file_name]['sect_num_top'].iloc[j]\n",
    "            try:\n",
    "                ref_section_def.append(deal_docs_dict[file_name]['deal_doc']['indenture']['Sections'][art_str][sect_num_top])\n",
    "            except:\n",
    "                print(i, file_name, j, art_str, sect_num_top, \" errored on Section Match\")\n",
    "                ref_section_def.append('No_Section_Match')\n",
    "                pass\n",
    "    except BaseException as e:\n",
    "        logger.error('Failed to do something: ' + str(e))\n",
    "        print(i, file_name, j)\n",
    "        df_refdefs_dict[file_name].iloc[j]\n",
    "    df_refdefs_dict[file_name]['ref_section_def'] = ref_section_def   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=deeppink> Incorporate ```df_refdefs_dict``` back into json files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Replace any ```def_values``` with a meaning reference in ```deal_docs_dict```**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, file_name in enumerate(file_name_list):\n",
    "    for i, term in enumerate(deal_docs_dict[file_name]['deal_doc']['indenture']['terms']):\n",
    "        for j, def_name in enumerate(df_refdefs_dict[file_name]['def_name']):\n",
    "            if term['term'] == def_name: \n",
    "                try: \n",
    "                    term['def_values'] =df_refdefs_dict[file_name]['ref_section_def'].iloc[j]\n",
    "                except:\n",
    "                    print(def_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Section 8.7  Reset  Amendments.    With  respect  to  any  supplemental  indenture \n",
      "which, by its terms (x) provides for an Optional Redemption, with Refinancing Proceeds, of all, \n",
      "but not less than all, Classes of the Secured Notes in whole, and not in part, and (y) is consented \n",
      "to  (and/or  directed)  by  both  the  Portfolio  Manager  and  the  Holders  of  a  Majority  of  the \n",
      "Aggregate  Outstanding  Amount  of  the  Subordinated  Notes  (the  “Requisite  Subordinated \n",
      "Noteholders”),  notwithstanding  anything  to  the  contrary  contained  herein,  the  Portfolio  Manager \n",
      "may,  with such consent of the Requisite Subordinated Noteholders, without regard to any other \n",
      "noteholder  consent  requirement  specified  in  this Indenture, cause such supplemental indenture to \n",
      "also (a) effect an extension of the end of the Reinvestment Period, (b) establish a non-call period \n",
      "for the replacement securities or loans issued to replace such Secured Notes or prohibit a future \n",
      "refinancing  of  such  replacement  securities,  (c)  modify  the  Weighted  Average  Life  Test,  (d) \n",
      "provide for a stated maturity of such replacement securities or loans that is later than the Stated \n",
      "Maturity of the Secured Notes, (e) effect an extension of the Stated Maturity of the Subordinated \n",
      "Notes,  and/or  (f)  make  any  other  supplements  or  amendments  to  this  Indenture  that  would \n",
      "otherwise  be  subject  to the noteholder consent rights of this Indenture (a “Reset Amendment”); \n",
      "provided  that  such  supplemental  indenture  may  not,  by  its  terms,  directly  modify  the  rights  or \n",
      "terms applicable to any portion of the Subordinated Notes in a manner intended to result in such \n",
      "rights or terms being materially different from any other portion of the Subordinated Notes. For \n",
      "the  avoidance  of  doubt,  (a)  Reset  Amendments  are  not  subject  to  any  noteholder  consent \n",
      "requirements  that  would  otherwise  apply  to  supplemental  indentures  described  in  this  Indenture \n",
      "and (b) no notice of a supplemental indenture that effects any Reset Amendment will be required \n",
      "to  be  provided  to  any  Holder  of  any  Class  of  Secured  Notes  being  refinanced  or  redeemed \n",
      "pursuant to the related Optional Redemption. \n"
     ]
    }
   ],
   "source": [
    "# Test if values references are populated in deal_doc \n",
    "for i, term in enumerate(deal_docs_dict[file_name_list[1]]['deal_doc']['indenture']['terms']):\n",
    "    if term['term'] == 'Requisite Subordinated Noteholders':\n",
    "        print(term['def_values'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=cyan>One-off json addition</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "deal_docs_dict[file_name_list[1]]['deal_doc']['_id'] = 'Vibrant CLO IX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_file_list[1], 'w') as f:\n",
    "    json.dump(deal_docs_dict[file_name_list[1]]['deal_doc'], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=cyan> Save down new json file. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save file in folder\n",
    "os.chdir(r'C:\\Users\\Owner\\OneDrive\\Digital Mosaic\\Product\\Solutions\\Vibrant\\Deal_Docs\\definitions')\n",
    "for i, file_name in enumerate(file_name_list):\n",
    "    json_file_name = json_file_list[i]\n",
    "    with open(json_file_name, 'w') as f:\n",
    "        json.dump(deal_docs_dict[file_name]['deal_doc'], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "client = MongoClient(\"mongodb+srv://dbadmin:creditSigma1030@creditsigma-2q7bl.mongodb.net/test?retryWrites=true&w=majority\")\n",
    "db = client.CreditSigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1 = db.document_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=cyan>One-off delete/insert</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.DeleteResult at 0x237d91b5d48>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x237d837dac8>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_query = { \"fileName\": file_name_list[1]}\n",
    "col1.delete_one(x_query)\n",
    "col1.insert_one(deal_docs_dict[file_name_list[1]]['deal_doc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.DeleteResult at 0x237d6f65e88>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<pymongo.results.DeleteResult at 0x237d91b1248>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<pymongo.results.DeleteResult at 0x237d91a6f88>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<pymongo.results.DeleteResult at 0x237d91b1fc8>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<pymongo.results.DeleteResult at 0x237d91b5988>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<pymongo.results.DeleteResult at 0x237d918d6c8>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<pymongo.results.DeleteResult at 0x237d91b1248>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<pymongo.results.DeleteResult at 0x237d91a6f88>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<pymongo.results.DeleteResult at 0x237d91b1fc8>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<pymongo.results.DeleteResult at 0x237d82fd448>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove one document \n",
    "# x_query = { \"fileName\": \"OHA Credit Funding 2 - Indenture(141188118_1).pdf\"}\n",
    "for i, file_name in enumerate(file_name_list):\n",
    "    x_query = { \"fileName\": file_name}\n",
    "    col1.delete_one(x_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x237d836bac8>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x237d83aabc8>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x237d8d9b1c8>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x237d83468c8>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x237d83187c8>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x237d82e1fc8>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x237d83b0a48>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x237d83a38c8>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x237d8d9b1c8>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x237d83aed08>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### insert deal_doc\n",
    "for i, file_name in enumerate(file_name_list):\n",
    "    col1.insert_one(deal_docs_dict[file_name]['deal_doc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
