{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable multiple output per cell. \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\Owner\\OneDrive\\Digital Mosaic\\Product\\Solutions\\Vibrant\\Deal_Docs')\n",
    "file_name = 'Vibrant CLO IX - Indenture.pdf'\n",
    "start_page = 8\n",
    "end_page = 73"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "roman_regex_list = [r\"[\\n\\s]\\(i\\)\", r\"[\\n\\s]\\(ii\\)\", r\"[\\n\\s]\\(iii\\)\", r\"[\\n\\s]\\(iv\\)\",\n",
    "                     r\"[\\n\\s]\\(v\\)\", r\"[\\n\\s]\\(vi\\)\", r\"[\\n\\s]\\(vii\\)\", r\"[\\n\\s]\\(viii\\)\", \n",
    "                    r\"[\\n\\s]\\(ix\\)\", r\"[\\n\\s]\\(x\\)\", r\"[\\n\\s]\\(xi\\)\", r\"[\\n\\s]\\(xii\\)\", \n",
    "                    r\"[\\n\\s]\\(xiii\\)\", r\"[\\n\\s]\\(xiv\\)\", r\"[\\n\\s]\\(xv\\)\", r\"[\\n\\s]\\(xvi\\)\", \n",
    "                    r\"[\\n\\s]\\(xvii\\)\", r\"[\\n\\s]\\(xviii\\)\", r\"[\\n\\s]\\(xix\\)\", r\"[\\n\\s]\\(xx\\)\", \n",
    "                    r\"[\\n\\s]\\(xxi\\)\", r\"[\\n\\s]\\(xxii\\)\", r\"[\\n\\s]\\(xxiii\\)\", r\"[\\n\\s]\\(xxiv\\)\",\n",
    "                    r\"[\\n\\s]\\(xxv\\)\", r\"[\\n\\s]\\(xxvi\\)\", r\"[\\n\\s]\\(xxvii\\)\", r\"[\\n\\s]\\(xxviii\\)\",\n",
    "                    r\"[\\n\\s]\\(xxix\\)\", r\"[\\n\\s]\\(xxx\\)\", r\"[\\n\\s]\\(xxxi\\)\", r\"[\\n\\s]\\(xxxii\\)\"\n",
    "                   ]\n",
    "\n",
    "roman_upper_regex_list =  [r\"[\\n\\s]\\(I\\)\", r\"[\\n\\s]\\(II\\)\", r\"[\\n\\s]\\(III\\)\", r\"[\\n\\s]\\(IV\\)\",\n",
    "                     r\"[\\n\\s]\\(V\\)\", r\"[\\n\\s]\\(VI\\)\", r\"[\\n\\s]\\(VII\\)\", r\"[\\n\\s]\\(VIII\\)\", \n",
    "                    r\"[\\n\\s]\\(IX\\)\", r\"[\\n\\s]\\(X\\)\", r\"[\\n\\s]\\(XI\\)\", r\"[\\n\\s]\\(XII\\)\", \n",
    "                    r\"[\\n\\s]\\(XIII\\)\", r\"[\\n\\s]\\(XIV\\)\", r\"[\\n\\s]\\(XV\\)\", r\"[\\n\\s]\\(XVI\\)\", \n",
    "                    r\"[\\n\\s]\\(XVII\\)\", r\"[\\n\\s]\\(XVIII\\)\", r\"[\\n\\s]\\(XIX\\)\", r\"[\\n\\s]\\(XX\\)\", \n",
    "                    r\"[\\n\\s]\\(XXI\\)\", r\"[\\n\\s]\\(XXII\\)\", r\"[\\n\\s]\\(XXIII\\)\",r\"[\\n\\s]\\(XXIV\\)\",\n",
    "                    r\"[\\n\\s]\\(XXV\\)\", r\"[\\n\\s]\\(XXVI\\)\", r\"[\\n\\s]\\(XXVII\\)\", r\"[\\n\\s]\\(XXVIII\\)\",\n",
    "                    r\"[\\n\\s]\\(XXIX\\)\", r\"[\\n\\s]\\(XXX\\)\", r\"[\\n\\s]\\(XXXI\\)\", r\"[\\n\\s]\\(XXXII\\)\"\n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loweralpha_regex_list = [r\"[\\n\\s]\\(a\\)\", r\"[\\n\\s]\\(b\\)\", r\"[\\n\\s]\\(c\\)\", r\"[\\n\\s]\\(d\\)\",\n",
    "                     r\"[\\n\\s]\\(e\\)\", r\"[\\n\\s]\\(f\\)\", r\"[\\n\\s]\\(g\\)\", r\"[\\n\\s]\\(h\\)\", \n",
    "                    r\"[\\n\\s]\\(i\\)\", r\"[\\n\\s]\\(j\\)\", r\"[\\n\\s]\\(k\\)\", r\"[\\n\\s]\\(l\\)\", \n",
    "                    r\"[\\n\\s]\\(m\\)\", r\"[\\n\\s]\\(n\\)\", r\"[\\n\\s]\\(o\\)\", r\"[\\n\\s]\\(p\\)\", \n",
    "                    r\"[\\n\\s]\\(q\\)\", r\"[\\n\\s]\\(r\\)\", r\"[\\n\\s]\\(s\\)\", r\"[\\n\\s]\\(t\\)\",\n",
    "                    r\"[\\n\\s]\\(u\\)\", r\"[\\n\\s]\\(v\\)\", r\"[\\n\\s]\\(w\\)\", r\"[\\n\\s]\\(x\\)\",\n",
    "                    r\"[\\n\\s]\\(y\\)\", r\"[\\n\\s]\\(z\\)\", r\"[\\n\\s]\\(aa\\)\", r\"[\\n\\s]\\(bb\\)\", \n",
    "                   ]\n",
    "\n",
    "upperalpha_regex_list = [r\"[\\n\\s]\\(A\\)\", r\"[\\n\\s]\\(B\\)\", r\"[\\n\\s]\\(C\\)\", r\"[\\n\\s]\\(D\\)\",\n",
    "                     r\"[\\n\\s]\\(E\\)\", r\"[\\n\\s]\\(F\\)\", r\"[\\n\\s]\\(G\\)\", r\"[\\n\\s]\\(H\\)\", \n",
    "                    r\"[\\n\\s]\\(I\\)\", r\"[\\n\\s]\\(J\\)\", r\"[\\n\\s]\\(K\\)\", r\"[\\n\\s]\\(L\\)\", \n",
    "                    r\"[\\n\\s]\\(M\\)\", r\"[\\n\\s]\\(N\\)\", r\"[\\n\\s]\\(O\\)\", r\"[\\n\\s]\\(P\\)\", \n",
    "                    r\"[\\n\\s]\\(Q\\)\", r\"[\\n\\s]\\(R\\)\", r\"[\\n\\s]\\(S\\)\", r\"[\\n\\s]\\(T\\)\",\n",
    "                    r\"[\\n\\s]\\(U\\)\", r\"[\\n\\s]\\(V\\)\", r\"[\\n\\s]\\(W\\)\", r\"[\\n\\s]\\(X\\)\",\n",
    "                    r\"[\\n\\s]\\(Y\\)\", r\"[\\n\\s]\\(Z\\)\", r\"[\\n\\s]\\(AA\\)\", r\"[\\n\\s]\\(BB\\)\", \n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract pages from both documents. \n",
    "doc_pages = scrape.pdf_extract_pages(file_name, start_page, end_page)\n",
    "doc_str = scrape.combine_strings(doc_pages) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isoalte locations for defintions and strings for each \n",
    "regex = r'“.*”:'\n",
    "df_defs = scrape.def_1st_tbl_indent(file_name, start_page, end_page, regex, roman_regex_list, loweralpha_regex_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>def_name</th>\n",
       "      <th>systemTerm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17g-5 Information Agent's Website</td>\n",
       "      <td>17g-5 Website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17g-5 Information Provider's Website</td>\n",
       "      <td>17g-5 Website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17g-5 Website</td>\n",
       "      <td>17g-5 Website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17g-5 Information Agent</td>\n",
       "      <td>17g-5 Information Agent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17g-5 Information Provider</td>\n",
       "      <td>17g-5 Information Agent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               def_name               systemTerm\n",
       "0     17g-5 Information Agent's Website            17g-5 Website\n",
       "1  17g-5 Information Provider's Website            17g-5 Website\n",
       "2                         17g-5 Website            17g-5 Website\n",
       "3               17g-5 Information Agent  17g-5 Information Agent\n",
       "4            17g-5 Information Provider  17g-5 Information Agent"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import mapping table \n",
    "os.chdir(r'C:\\Users\\Owner\\OneDrive\\Digital Mosaic\\Product\\Solutions\\Vibrant\\Deal_Docs\\definitions')\n",
    "df_fldmap = pd.read_csv('Deal_def_columns_fld_map.csv', encoding='cp1252')\n",
    "df_fldmap.columns = ['def_name', 'systemTerm']\n",
    "df_fldmap.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: def_name, dtype: object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean up definitions and remap\n",
    "df_defs = scrape.df_def_cleanup(df_defs)\n",
    "# rename columns to match df_defs to merge after \n",
    "df_def_stage = pd.merge(df_defs, df_fldmap, on='def_name', how='left')\n",
    "df_def_stage[df_def_stage['systemTerm'].isnull()]['def_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>def_name</th>\n",
       "      <th>def_description</th>\n",
       "      <th>page_num</th>\n",
       "      <th>roman_bullets_loc</th>\n",
       "      <th>letter_bullets_loc</th>\n",
       "      <th>systemTerm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17g-5 Information Provider</td>\n",
       "      <td>The Trustee.</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17g-5 Information Agent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17g-5 Information Provider's Website</td>\n",
       "      <td>The  internet  website  of  the  17g-5 \\nI...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17g-5 Website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acceleration Event</td>\n",
       "      <td>The meaning  specified  in Section 5.4(a).</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Acceleration Event</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Accountants' Report</td>\n",
       "      <td>An agreed-upon procedures report from the fi...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Accountants' Report</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accountants' Report</td>\n",
       "      <td>An agreed-upon procedures report from the fi...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Accountants' Report</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               def_name  \\\n",
       "0            17g-5 Information Provider   \n",
       "1  17g-5 Information Provider's Website   \n",
       "2                    Acceleration Event   \n",
       "3                   Accountants' Report   \n",
       "4                   Accountants' Report   \n",
       "\n",
       "                                     def_description  page_num  \\\n",
       "0                                      The Trustee.         11   \n",
       "1      The  internet  website  of  the  17g-5 \\nI...        11   \n",
       "2        The meaning  specified  in Section 5.4(a).         11   \n",
       "3    An agreed-upon procedures report from the fi...        11   \n",
       "4    An agreed-upon procedures report from the fi...        11   \n",
       "\n",
       "   roman_bullets_loc  letter_bullets_loc               systemTerm  \n",
       "0                  0                   0  17g-5 Information Agent  \n",
       "1                  0                   0            17g-5 Website  \n",
       "2                  0                   0       Acceleration Event  \n",
       "3                  0                   0      Accountants' Report  \n",
       "4                  0                   0      Accountants' Report  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_def_stage.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scrape' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6eb6111bd439>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_def_comb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscrape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdef_first_bullet_combine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_def_stage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroman_regex_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloweralpha_regex_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdef_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscrape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdef_pop_firstdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_def_comb\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# convert to dictionary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scrape' is not defined"
     ]
    }
   ],
   "source": [
    "df_def_comb = scrape.def_first_bullet_combine(df_def_stage, roman_regex_list, loweralpha_regex_list)\n",
    "def_dict = scrape.def_pop_firstdict(df_def_comb)  # convert to dictionary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exception Processing in definitions\n",
    "Several definitions imported code from page pin directly into the name. these need to be scraped manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dollar, USD or U.S.$\n",
      "U.S. person\n"
     ]
    }
   ],
   "source": [
    "# test out function to find periods \n",
    "for key in def_dict.keys():\n",
    "    if \".\" in key:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = steelblue> Table of Contents Processing </font>\n",
    "Isolate **<font color=cyan>page numbers</font>** for each Article and load into ```section_pages``` list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\Owner\\OneDrive\\Digital Mosaic\\Product\\Solutions\\Vibrant\\Deal_Docs')\n",
    "file_name = 'Vibrant CLO IX - Indenture.pdf'\n",
    "toc_start_page = 1\n",
    "toc_end_page = 6\n",
    "toc_pages = scrape.pdf_extract_pages(file_name, toc_start_page, toc_end_page)\n",
    "toc_str = scrape.combine_strings(toc_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Section 1.1(\\s+).*(\\.*)\\d+\n",
      "\n",
      "Section 2.1(\\s+).*(\\.*)\\d+\n",
      "\n",
      "Section 3.1(\\s+).*(\\.*)\\d+\n",
      "\n",
      "Section 4.1(\\s+).*(\\.*)\\d+\n",
      "\n",
      "Section 5.1(\\s+).*(\\.*)\\d+\n",
      "\n",
      "Section 6.1(\\s+).*(\\.*)\\d+\n",
      "\n",
      "Section 7.1(\\s+).*(\\.*)\\d+\n",
      "\n",
      "Section 8.1(\\s+).*(\\.*)\\d+\n",
      "\n",
      "Section 9.1(\\s+).*(\\.*)\\d+\n",
      "\n",
      "Section 10.1(\\s+).*(\\.*)\\d+\n",
      "\n",
      "Section 11.1(\\s+).*(\\.*)\\d+\n",
      "\n",
      "Section 12.1(\\s+).*(\\.*)\\d+\n",
      "\n",
      "Section 13.1(\\s+).*(\\.*)\\d+\n",
      "\n",
      "Section 14.1(\\s+).*(\\.*)\\d+\n",
      "\n",
      "Section 15.1(\\s+).*(\\.*)\\d+\n"
     ]
    }
   ],
   "source": [
    "toc_dict = {}\n",
    "num_sections = 15\n",
    "sec1_name_list = []\n",
    "regex_page = r'\\.*\\d+'\n",
    "for i in np.arange(1, num_sections+1):\n",
    "    article_name = \"ARTICLE \" + str(i)\n",
    "    regex_sec1 = \"\\nSection \" + str(i) + \".1\"\n",
    "    regex_sec1 = regex_sec1 + r\"(\\s+).*(\\.*)\\d+\"\n",
    "    print(regex_sec1) \n",
    "    match = re.search(regex_sec1, toc_str)\n",
    "        # process page numbers\n",
    "    pg_str = toc_str[match.span()[1]-5:match.span()[1]]\n",
    "    pg_loc = re.search(regex_page, pg_str)\n",
    "    pg_num = pg_str[pg_loc.span()[0]:pg_loc.span()[1]]\n",
    "    pg_num = pg_num.replace('.','')\n",
    "    pg_num = int(pg_num) \n",
    "    toc_dict[article_name] = pg_num "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ARTICLE 1': 2,\n",
       " 'ARTICLE 2': 70,\n",
       " 'ARTICLE 3': 97,\n",
       " 'ARTICLE 4': 102,\n",
       " 'ARTICLE 5': 104,\n",
       " 'ARTICLE 6': 116,\n",
       " 'ARTICLE 7': 130,\n",
       " 'ARTICLE 8': 155,\n",
       " 'ARTICLE 9': 165,\n",
       " 'ARTICLE 10': 176,\n",
       " 'ARTICLE 11': 195,\n",
       " 'ARTICLE 12': 203,\n",
       " 'ARTICLE 13': 211,\n",
       " 'ARTICLE 14': 212,\n",
       " 'ARTICLE 15': 221}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=lightsalmon> Sections Processing </font> \n",
    "1. 15 Total articless\n",
    "2. Opening section length is 6 pages: Covers Title + Table Contents and is the number of pages before the document starts counting pages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[77, 104, 109, 111, 123, 137, 162, 172, 183, 202, 210, 218, 219, 228]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# populate section_pages list \n",
    "section_pages = []\n",
    "for i in np.arange(2, len(toc_dict.keys())+1): \n",
    "    art_str = 'ARTICLE ' + str(i)\n",
    "    section_pages.append(toc_dict[art_str])\n",
    "# add opening length to section pages\n",
    "opening_length = 7\n",
    "section_pages = [x + opening_length for x in section_pages]   # add opening length (# of pages in title + toc) to each page\n",
    "sec_page_last = 231   # last page of sections\n",
    "section_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec2_regex_list = [r'[\\n\\s]Section 2.1(\\s)', r'[\\n\\s]Section 2.2(\\s)', \n",
    "                   r'[\\n\\s]Section 2.3(\\s)', r'[\\n\\s]Section 2.4(\\s)',\n",
    "                  r'[\\n\\s]Section 2.5(\\s)', r'[\\n\\s]Section 2.6(\\s)',\n",
    "                  r'[\\n\\s]Section 2.7(\\s)', r'[\\n\\s]Section 2.8(\\s)',\n",
    "                  r'[\\n\\s]Section 2.9(\\s)',r'[\\n\\s]Section 2.10(\\s)',\n",
    "                  r'[\\n\\s]Section 2.11(\\s)', r'[\\n\\s]Section 2.12(\\s)',\n",
    "                  r'[\\n\\s]Section 2.13(\\s)', r'[\\n\\s]Section 2.14(\\s)',\n",
    "                  r'[\\n\\s]Section 2.15(\\s)', r'[\\n\\s]Section 2.16(\\s)',\n",
    "                  r'[\\n\\s]Section 2.17(\\s)', r'[\\n\\s]Section 2.18(\\s)',\n",
    "                  r'[\\n\\s]Section 2.19(\\s)', r'[\\n\\s]Section 2.20(\\s)',\n",
    "                  r'[\\n\\s]Section 2.21(\\s)', r'[\\n\\s]Section 2.22(\\s)',\n",
    "                  r'[\\n\\s]Section 2.23(\\s)', r'[\\n\\s]Section 2.24(\\s)',\n",
    "                  r'[\\n\\s]Section 2.25(\\s)', r'[\\n\\s]Section 2.26(\\s)',\n",
    "                  r'[\\n\\s]Section 2.27(\\s)', r'[\\n\\s]Section 2.28(\\s)',\n",
    "                  r'[\\n\\s]Section 2.29(\\s)', r'[\\n\\s]Section 2.30(\\s)']\n",
    "numdec_list = ['1.','2.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Section Titles List\n",
    "section_titles = ['2_THE NOTES','3_CONDITIONS PRECEDENT', '4_SATISFACTION AND DISCHARGE',\n",
    "                 '5_REMEDIES', '6_THE TRUSTEE','7_COVENANTS','8_SUPPLEMENTAL INDENTURES',\n",
    "                 '9_REDEMPTION OF NOTES','10_ACCOUNTS, ACCOUNTINGS, AND RELEASES',\n",
    "                 '11_APPLICATION OF MONIES','12_PURCHASE AND SALE OF COLLATERAL OBLIGATIONS',\n",
    "                 \"13_HOLDER'S RELATIONS\", '14_MISCELANNEOUS', \n",
    "                  '15_ASSIGNMENT OF CERTAIN AGREEMENTS']\n",
    "                  # '16_Hedge Agreements']\n",
    "len(section_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate list of regex lists\n",
    "sec_reglist_dict = {}\n",
    "start_sec = 2    # First Article to reference\n",
    "end_sec = len(section_pages) + start_sec \n",
    "for i in np.arange(start_sec, end_sec):\n",
    "    rep_str = str(i)+'.'\n",
    "    sec_name = \"Article \" + str(i)\n",
    "    sec_rep_list = [reg.replace('2.',rep_str) for reg in sec2_regex_list]\n",
    "    sec_reglist_dict[sec_name] = sec_rep_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Article 2', 'Article 3', 'Article 4', 'Article 5', 'Article 6', 'Article 7', 'Article 8', 'Article 9', 'Article 10', 'Article 11', 'Article 12', 'Article 13', 'Article 14', 'Article 15'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sec_reglist_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find regexes to mark end of each section**<br> \n",
    "This will be beginning next Article sections. for last section, look for start of Schedules section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_pages = scrape.pdf_extract_pages(file_name, section_pages[0], sec_page_last)\n",
    "articles_str = scrape.combine_strings(articles_pages) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex_art = r'[\\s\\n]ARTICLE\\s.*\\n'\n",
    "regex_art = r'ARTICLE\\s.*\\n'\n",
    "loc_list = scrape.text_match_2list(regex_art, articles_str)\n",
    "art_end_strlist = [articles_str[x[0]:x[1]+5] for x in loc_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ARTICLE 3 \\n \\nCON',\n",
       " 'ARTICLE 4 \\n \\nSAT',\n",
       " 'ARTICLE 5 \\n \\nREM',\n",
       " 'ARTICLE 6 \\n \\nTHE',\n",
       " 'ARTICLE 7 \\n \\nCOV',\n",
       " 'ARTICLE 8 \\n \\nSUP',\n",
       " 'ARTICLE 9 \\n \\nRED',\n",
       " 'ARTICLE 10 \\n \\nACC',\n",
       " 'ARTICLE 11 \\n \\nAPP',\n",
       " 'ARTICLE 12 \\n \\nSAL',\n",
       " 'ARTICLE 13 \\n \\nHOL',\n",
       " 'ARTICLE 14 \\n \\nMIS',\n",
       " 'ARTICLE 15 \\n \\nASS']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# art_end_strlist.remove('ARTICLE 2(1) OF THE HAGUE CONVENTION ON THE LAW APPLICABLE TO \\nCERTA')\n",
    "art_end_strlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=lightsalmon> Populate Articles Dictionary </font> \n",
    "1. Process all sections excepet last one. \n",
    "2. Process last section "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_sec_dict = {}   #holds sections within indenture. will populate with article \n",
    "start_sec = 0\n",
    "end_sec = len(section_pages)-1\n",
    "for i in np.arange(start_sec, end_sec):\n",
    "    art_dict = {}\n",
    "    art_dict['Name'] = section_titles[i]\n",
    "    sec_name = 'Article ' + str(i+2)\n",
    "    art_pages = scrape.pdf_extract_pages(file_name, section_pages[i]-1, section_pages[i+1])\n",
    "    art_str = scrape.combine_strings(art_pages)\n",
    "    # art_str = art_str.replace(page_pin, '\\n')\n",
    "    # art_dict['Section'] = art_str\n",
    "    regex_end = art_end_strlist[i]\n",
    "    end_loc = re.search(regex_end, art_str).span()[0]-1\n",
    "    art_bullets = scrape.list_btn_loc_regexlist_keepbullet2_order(art_str, end_loc, sec_reglist_dict[sec_name])\n",
    "    art_bullet_names = [str(i+2) + '_' + str(x) for x in np.arange(len(art_bullets)) + 1]\n",
    "    # art_dict['art_bullet_names'] = art_bullet_names\n",
    "    for j, bullet in enumerate(art_bullets):\n",
    "        art_dict[art_bullet_names[j]] = bullet\n",
    "    ind_sec_dict[sec_name] = art_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article 2 dict_keys(['Name', '2_1', '2_2', '2_3', '2_4', '2_5', '2_6', '2_7', '2_8', '2_9', '2_10', '2_11', '2_12', '2_13'])\n",
      "Article 3 dict_keys(['Name', '3_1', '3_2', '3_3'])\n",
      "Article 4 dict_keys(['Name', '4_1', '4_2', '4_3'])\n",
      "Article 5 dict_keys(['Name', '5_1', '5_2', '5_3', '5_4', '5_5', '5_6', '5_7', '5_8', '5_9', '5_10', '5_11', '5_12', '5_13', '5_14', '5_15', '5_16', '5_17', '5_18'])\n",
      "Article 6 dict_keys(['Name', '6_1', '6_2', '6_3', '6_4', '6_5', '6_6', '6_7', '6_8', '6_9', '6_10', '6_11', '6_12', '6_13', '6_14', '6_15', '6_16', '6_17'])\n",
      "Article 7 dict_keys(['Name', '7_1', '7_2', '7_3', '7_4', '7_5', '7_6', '7_7', '7_8', '7_9', '7_10', '7_11', '7_12', '7_13', '7_14', '7_15', '7_16', '7_17', '7_18', '7_19', '7_20', '7_21'])\n",
      "Article 8 dict_keys(['Name', '8_1', '8_2', '8_3', '8_4', '8_5', '8_6', '8_7'])\n",
      "Article 9 dict_keys(['Name', '9_1', '9_2', '9_3', '9_4', '9_5', '9_6', '9_7'])\n",
      "Article 10 dict_keys(['Name', '10_1', '10_2', '10_3', '10_4', '10_5', '10_6', '10_7', '10_8', '10_9', '10_10', '10_11', '10_12'])\n",
      "Article 11 dict_keys(['Name', '11_1'])\n",
      "Article 12 dict_keys(['Name', '12_1', '12_2', '12_3', '12_4'])\n",
      "Article 13 dict_keys(['Name', '13_1', '13_2'])\n",
      "Article 14 dict_keys(['Name', '14_1', '14_2', '14_3', '14_4', '14_5', '14_6', '14_7', '14_8', '14_9', '14_10', '14_11', '14_12', '14_13', '14_14', '14_15', '14_16', '14_17'])\n"
     ]
    }
   ],
   "source": [
    "for key in ind_sec_dict.keys():\n",
    "    print(key,ind_sec_dict[key].keys() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'14_MISCELANNEOUS'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_sec_dict['Article 14']['Name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=lightsalmon> Populate Last Article: Article 15 </font> \n",
    "Process last article. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "artlast_pages = scrape.pdf_extract_pages(file_name, section_pages[len(section_pages)-2], sec_page_last)\n",
    "artlast_str = scrape.combine_strings(artlast_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate bullets\n",
    "last_section = 'Article 15'\n",
    "artlast_bullets = scrape.list_btn_loc_regexlist_keepbullet2_order(artlast_str, len(artlast_str), sec_reglist_dict[last_section])\n",
    "# populate Article 15 Dictionary\n",
    "artlast_dict = {}\n",
    "artlast_dict['Name'] = section_titles[len(section_titles)-1]\n",
    "sec15_bullet_names = ['15_1']\n",
    "for i, bullet in enumerate(artlast_bullets):\n",
    "    artlast_dict[sec15_bullet_names[i]] = bullet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_article = 'Article ' + str(len(sec_reglist_dict.keys())+1)\n",
    "ind_sec_dict[last_article] = artlast_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=cyan> Prep Definitions and Sections for Mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "deal_dict = {}\n",
    "deal_dict['_id'] = 'Vibrant CLO IX'\n",
    "deal_dict['fileName'] = file_name\n",
    "deal_dict['fileType'] = 'Indenture Review'\n",
    "deal_dict['deal'] = 'Vibrant CLO IX LTD'\n",
    "deal_dict['status'] = 'Completed'\n",
    "\n",
    "indent_dict = {}\n",
    "indent_dict['terms'] = def_dict\n",
    "indent_dict['Sections'] = ind_sec_dict\n",
    "deal_dict['indenture'] = indent_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['_id', 'fileName', 'fileType', 'deal', 'status', 'indenture'])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deal_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page_num': 28,\n",
       " 'systemTerm': 'Custodial Account',\n",
       " 'text': '    The  custodial  account  established  pursuant  to \\nSection 10.3(b). ',\n",
       " 'def_values': '    The  custodial  account  established  pursuant  to \\nSection 10.3(b). '}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deal_dict['indenture']['terms']['Custodial Account']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export dictionary to excel\n",
    "1. Convert ```def_dict``` into Dataframe \n",
    "2. Export as excel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_def_dict = pd.DataFrame.from_dict(def_dict, orient='index')\n",
    "df_def_dict.to_excel('def_dict_Vibrant_IX.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export file to Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        elif isinstance(obj, pd.DataFrame):\n",
    "            return obj.to_json()\n",
    "        else:\n",
    "            return super(NpEncoder, self).default(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json file\n",
    "jfile = json.dumps(deal_dict, cls = NpEncoder)\n",
    "jdict = json.loads(jfile) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['_id', 'fileName', 'fileType', 'deal', 'status', 'indenture'])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jdict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change names\n",
    "for key in jdict['indenture']['terms'].keys():\n",
    "    new_name = key.replace(\"U.S.\", \"US\")\n",
    "    jdict['indenture']['terms'][new_name] = jdict['indenture']['terms'].pop(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'jdict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ba0da62b14ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# check keys for period\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mjdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'indenture'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'terms'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m\".\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'jdict' is not defined"
     ]
    }
   ],
   "source": [
    "# check keys for period \n",
    "for key in jdict['indenture']['terms'].keys():\n",
    "    if \".\" in key:\n",
    "        print(key) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save file in folder\n",
    "os.chdir(r'C:\\Users\\Owner\\OneDrive\\Digital Mosaic\\Product\\Solutions\\Vibrant\\Deal_Docs\\definitions')\n",
    "with open('Vibrant_IX.json', 'w') as f:\n",
    "    json.dump(jdict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=cyan> Import into Mongo </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "client = MongoClient(\"mongodb+srv://dbadmin:creditSigma1030@creditsigma-2q7bl.mongodb.net/test?retryWrites=true&w=majority\")\n",
    "db = client.CreditSigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x22b905137c8>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col1 = db.document\n",
    "col1.insert_one(jdict)\n",
    "# view file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=cyan> Mongo: Editing / Deleting Documents </font> \n",
    "1. delete document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIBRANT_VIII_indenture.pdf\n",
      "5ec5e8c29a32121c6c3367ea\n",
      "OHA_XII_Indenture.pdf\n",
      "5ec5f7b5e5fea830f3710320\n",
      "\n",
      "5ec5fa73e5fea830f3710321\n",
      "\n",
      "5ec5fb3fe5fea830f3710322\n",
      "OHA Credit Funding 2 - Indenture(141188118_1).pdf\n",
      "5eff8cbc1afd59a3f7c352a7\n",
      "OHA XII Indenture.pdf\n",
      "5effaff5b4fd9bd17e3bc234\n",
      "Vibrant VIII - Indenture(133849278_1).pdf\n",
      "5effb569a81d4f49caeec677\n",
      "PAIA 2018-1 - Indenture (730498612_1).pdf\n",
      "5effc18d0a6885c3752c4fbe\n",
      "Crestline Denali CLO XVII, Ltd-Indenture.pdf\n",
      "5effd73898754283178393a6\n",
      "Carlyle 2019-1 Indenture (Executed).pdf\n",
      "5f00c13553691bc600c4422c\n",
      "ohacp11-INDENTURE-2015-11-30-755682.pdf\n",
      "5f00e9201100153dfeeaf124\n",
      "THL 2019-3 - Indenture (with exhibits).pdf\n",
      "5f01f2e4a96ffb458e43552d\n",
      "Vibrant CLO X - Indenture(137699931_1)[1].pdf\n",
      "5f051a276ebf30c57ce01837\n",
      "Vibrant CLO IX - Indenture.pdf\n",
      "Vibrant CLO IX\n"
     ]
    }
   ],
   "source": [
    "# print list of documents\n",
    "col1 = db.document\n",
    "doc_list = col1.find({}) # returns iterable cursor type\n",
    "for doc in doc_list:\n",
    "    print(doc['fileName'])\n",
    "    print(doc['_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.DeleteResult at 0x22b98b05208>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove one document \n",
    "x_query = { \"fileName\": \"Vibrant CLO IX - Indenture.pdf\" }\n",
    "col1.delete_one(x_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
